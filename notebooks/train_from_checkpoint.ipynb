{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "Ipie3WVKB9E5",
    "outputId": "c4df477c-9657-4a5c-9c82-faa7133d5286"
   },
   "outputs": [],
   "source": [
    "!wget http://www.openslr.org/resources/12/dev-clean.tar.gz\n",
    "!tar xzf dev-clean.tar.gz\n",
    "!sudo apt-get install tree -y\n",
    "!pip install soundfile\n",
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "is0KGk5uCZ1R",
    "outputId": "84daddc7-fb52-43d9-c0fa-80df6006a944"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DoWTomlRB_fz"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import soundfile as sf\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import permutations\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import IPython\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D, Flatten\n",
    "from tensorflow.keras.layers import GRU, Bidirectional, BatchNormalization, Reshape, Concatenate,concatenate, Average\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "85AcqkODCESY"
   },
   "outputs": [],
   "source": [
    "def graph_spectrogram(wav_file):\n",
    "    rate, data = get_wav_info(wav_file)\n",
    "    nfft = 200 # Length of each window segment\n",
    "    fs = 8000 # Sampling frequencies\n",
    "    noverlap = 120 # Overlap between windows\n",
    "    nchannels = data.ndim\n",
    "    if nchannels == 1:\n",
    "        pxx, freqs, bins, im = plt.specgram(data, nfft, fs, noverlap = noverlap)\n",
    "    elif nchannels == 2:\n",
    "        pxx, freqs, bins, im = plt.specgram(data[:,0], nfft, fs, noverlap = noverlap)\n",
    "    return pxx\n",
    "\n",
    "# Load a wav file\n",
    "def get_wav_info(wav_file):\n",
    "    rate, data = wavfile.read(wav_file)\n",
    "    return rate, data\n",
    "\n",
    "def process_sliding_window(flac_file, processed_directory_path,filename):\n",
    "    window_size = 1600\n",
    "    step_size = 800\n",
    "    actual_idx = 0\n",
    "    amount_of_files = 0\n",
    "    new_base_directory = processed_directory_path +filename[:-5]+\"/\"\n",
    "    new_base_path = (new_base_directory+filename)[:-5]\n",
    "\n",
    "    if not os.path.exists(new_base_directory):\n",
    "        \tos.makedirs(new_base_directory)\n",
    "\n",
    "    while(len(flac_file) > actual_idx + window_size):\n",
    "        flac_file[actual_idx:actual_idx+window_size].export(new_base_path+'_'+str(amount_of_files) + '.wav',format='wav')\n",
    "        amount_of_files += 1\n",
    "        actual_idx += step_size\n",
    "    if (actual_idx + window_size - len(flac_file) > window_size/2 and len(flac_file) > window_size):\n",
    "        flac_file[-window_size:].export(new_base_path+'_'+str(amount_of_files) + '.wav',format='wav')\n",
    "        \n",
    "\n",
    "def make_processed_dataset(libri_speech_path,processed_libri_speech_path):\n",
    "    dev_path = libri_speech_path + \"dev-clean/\"\n",
    "    processed_dev_path = processed_libri_speech_path + \"dev-clean/\"\n",
    "    voice_count = 0\n",
    "    for voice in (os.listdir(dev_path)):\n",
    "        voice_path = dev_path + voice + \"/\"\n",
    "        for chapter in (os.listdir(voice_path)):\n",
    "            chapter_path = voice_path + chapter + \"/\"\n",
    "            for filename in os.listdir(chapter_path):\n",
    "                processed_directory_path = processed_dev_path + voice + \"/\" + chapter + \"/\" \n",
    "                if filename.endswith(\"flac\"):\n",
    "                    flac_file = AudioSegment.from_file(chapter_path + filename, \"flac\")\n",
    "                    process_sliding_window(flac_file,processed_directory_path,filename)\n",
    "        voice_count += 1\n",
    "        print (\"actual progress\", str (int(voice_count/len(os.listdir(dev_path))*100)), ('%'))\n",
    "        \n",
    "def process_16_dataset_main():\n",
    "    dataset_base_path = \"./\"\n",
    "    libri_speech_path = dataset_base_path + \"LibriSpeech/\"\n",
    "    processed_libri_speech_path = dataset_base_path + \"16_LibriSpeech/\"\n",
    "    make_processed_dataset(libri_speech_path, processed_libri_speech_path)\n",
    "\n",
    "\n",
    "def make_numpy_XY(libri_speech_path):\n",
    "    dev_path = libri_speech_path + \"dev-clean/\"\n",
    "    voice_count = 0\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    for voice in (os.listdir(dev_path)):\n",
    "        voice_path = dev_path + voice + \"/\"\n",
    "        count = 0     \n",
    "        X_5 = []\n",
    "        for chapter in (os.listdir(voice_path)):\n",
    "            chapter_path = voice_path + chapter + \"/\"\n",
    "            for uterrance in os.listdir(chapter_path):\n",
    "              uterrance_path = chapter_path + uterrance + \"/\"\n",
    "              for filename in os.listdir(uterrance_path):\n",
    "                if filename.endswith(\"wav\"):\n",
    "                    count += 1\n",
    "                    wav_file = graph_spectrogram(uterrance_path + filename)\n",
    "                    X_5.append(wav_file)\n",
    "                if (count % 5 == 0 and count != 0):\n",
    "                    X.append(X_5)\n",
    "                    X_5 = []\n",
    "                    Y.append(voice)\n",
    "                if (count >= 100):\n",
    "                    break\n",
    "            if count>=100:\n",
    "                break\n",
    "        voice_count+=1\n",
    "        print (\"actual progress\", str (int(voice_count/len(os.listdir(dev_path))*100)), ('%'))\n",
    "    return X,Y\n",
    "\n",
    "def process_numpy_XY():\n",
    "    dataset_base_path = \"./\"\n",
    "    processed_libri_speech_path = dataset_base_path + \"16_LibriSpeech/\"\n",
    "    X,Y = make_numpy_XY(processed_libri_speech_path)\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    return X,Y\n",
    "\n",
    "def reshape_X(X):\n",
    "    examples = X.shape[0]\n",
    "    dimension = X.shape[1]\n",
    "    time = X.shape[2]\n",
    "    freq = X.shape[3]\n",
    "    new_X = np.zeros((dimension,examples,time,freq))\n",
    "    for m in range(examples):\n",
    "        for d in range(dimension):\n",
    "            new_X[d][m] = X[m][d]\n",
    "    return new_X\n",
    "    \n",
    "    \n",
    "def load_numpy_XY():\n",
    "    X_path = './preprocessed/X_total.npy'\n",
    "    Y_path = './preprocessed/Y_total.npy'\n",
    "    X = np.load(X_path)\n",
    "    Y = np.load(Y_path)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1714
    },
    "colab_type": "code",
    "id": "Ea8002vLCK20",
    "outputId": "456c83d1-0739-4772-abaf-f1116f76fa58"
   },
   "outputs": [],
   "source": [
    "print ('processing dataset:')\n",
    "process_16_dataset_main()\n",
    "print ('----------------')\n",
    "print ('Making XY:')\n",
    "X,Y = process_numpy_XY()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "m1c_rgPgCzN_",
    "outputId": "3970f28f-2188-44cb-dff2-ddc6ccd71c9a"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "SBv4AZlfC4AZ",
    "outputId": "427bc2ee-ef8e-4e4f-aca3-aea7b326aaf7"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "base_model = load_model('./base_model_100plus.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XyENxXH0KYxA"
   },
   "outputs": [],
   "source": [
    "def five_average_model(input_shape,base_model):\n",
    "  model_inputs = []\n",
    "  model_results = []\n",
    "  for i in range(5):\n",
    "    X_input = Input(shape = input_shape, name = \"Input\"+ str(i))\n",
    "    model_inputs.append(X_input)\n",
    "    result = base_model(X_input)\n",
    "    model_results.append(result)\n",
    "    \n",
    "  X = Average()(model_results)\n",
    "  model = Model(inputs = model_inputs,outputs = X)\n",
    "  \n",
    "  return model\n",
    "\n",
    "def cosine_similarity(u, v):\n",
    "    \"\"\"\n",
    "    Cosine similarity reflects the degree of similariy between u and v\n",
    "        \n",
    "    Arguments:\n",
    "        u -- a word vector of shape (n,)          \n",
    "        v -- a word vector of shape (n,)\n",
    "\n",
    "    Returns:\n",
    "        cosine_similarity -- the cosine similarity between u and v defined by the formula above.\n",
    "    \"\"\"\n",
    "    \n",
    "    distance = 0.0\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Compute the dot product between u and v (≈1 line)\n",
    "    dot = np.dot(u,v)\n",
    "    # Compute the L2 norm of u (≈1 line)\n",
    "    norm_u = np.linalg.norm(u)\n",
    "    # Compute the L2 norm of v (≈1 line)\n",
    "    norm_v = np.linalg.norm(v)\n",
    "    # Compute the cosine similarity defined by formula (1) (≈1 line)\n",
    "    cosine_similarity = dot/(norm_u*norm_v)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cosine_similarity\n",
    "\n",
    "  \n",
    "def triplet_loss(y_true, y_pred, alpha = 0.35):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss as defined by formula (3)\n",
    "    \n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
    "            positive -- the encodings for the positive images, of shape (None, 128)\n",
    "            negative -- the encodings for the negative images, of shape (None, 128)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    total_lenght = 64*3\n",
    "    anchor, positive, negative = y_pred[:,0:int(total_lenght*1/3)],y_pred[:,int(total_lenght*1/3):int(total_lenght*2/3)],y_pred[:,int(total_lenght*2/3):int(total_lenght*3/3)]\n",
    "    ### START CODE HERE ### (≈ 4 lines)\n",
    "    '''\n",
    "    # Step 1: Compute the (encoding) distance between the anchor and the positive, you will need to sum over axis=-1\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)))\n",
    "    # Step 2: Compute the (encoding) distance between the anchor and the negative, you will need to sum over axis=-1\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)))\n",
    "    # Step 3: subtract the two previous distances and add alpha.\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist,neg_dist),alpha)\n",
    "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss,0.0))\n",
    "    ### END CODE HERE ###\n",
    "    '''\n",
    "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
    "\n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
    "\n",
    "    # compute loss\n",
    "    basic_loss = pos_dist-neg_dist+alpha\n",
    "    loss = K.sum(K.maximum(basic_loss,0.0))\n",
    "    \n",
    "    return loss\n",
    "#     print('total_lenght=',  total_lenght)\n",
    "#     total_lenght =12\n",
    "\n",
    "def speech_model(input_shape, average_model):\n",
    "    \"\"\"\n",
    "    Function creating the model's graph in Keras.\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "    base_model -- model to be used to call the inputs\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    #get triplets vectors\n",
    "    input_anchor = []\n",
    "    input_positive = []\n",
    "    input_negative = []\n",
    "    for i in range(15):\n",
    "        X_input = Input(shape = input_shape, name = \"Input\"+ str(i))\n",
    "        if (i < 5):\n",
    "            input_anchor.append(X_input)\n",
    "        elif (i < 10):\n",
    "            input_positive.append(X_input)\n",
    "        elif(i < 15):\n",
    "            input_negative.append(X_input)\n",
    "\n",
    "    vec_anchor = average_model(input_anchor)\n",
    "    vec_positive = average_model(input_positive)\n",
    "    vec_negative = average_model(input_negative)\n",
    "    \n",
    "    #Concatenate vectors vec_positive, vec_negative\n",
    "    concat_layer = concatenate([vec_anchor,vec_positive,vec_negative], axis = -1, name='concat_layer')\n",
    "    \n",
    "    model = Model(inputs = input_anchor + input_positive + input_negative, outputs = concat_layer, name = 'speech_to_vec')\n",
    "    #model = Model(inputs = input_anchor + input_positive + input_negative, outputs = [vec_anchor,vec_positive,vec_negative], name = 'speech_to_vec')\n",
    "    #model = Model(inputs = [input_anchor,input_positiv], outputs=vec_anchor)\n",
    "    \n",
    "    \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N887K5OqKq-R"
   },
   "outputs": [],
   "source": [
    "d = 5\n",
    "Tx = 318\n",
    "n_freq = 101\n",
    "\n",
    "average_model = five_average_model(input_shape = (n_freq, Tx), base_model = base_model)\n",
    "speech_model = speech_model(input_shape = (n_freq, Tx), average_model = average_model) \n",
    "speech_model.compile(loss=triplet_loss, optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "OXoKTLbAK7rP",
    "outputId": "5ef381ef-8eb9-40b8-df8f-588607ac297a"
   },
   "outputs": [],
   "source": [
    "print (X.shape)\n",
    "X_train, X_test = [], []\n",
    "Y_train, Y_test = [], []\n",
    "for i in range (X.shape[0]):\n",
    "    if np.random.random() < 0.8:\n",
    "        X_train.append(X[i])\n",
    "        Y_train.append(Y[i])\n",
    "    else:\n",
    "        X_test.append(X[i])\n",
    "        Y_test.append(Y[i])\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XRMtgtOtLET4"
   },
   "outputs": [],
   "source": [
    "X_train = reshape_X(X_train)\n",
    "X_test = reshape_X(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "58n69smOLHHO",
    "outputId": "fcd30e29-f969-4857-e271-ef2eb706074b"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "!mkdir preprocessed\n",
    "np.save('./preprocessed/X_train',X_train)\n",
    "np.save('./preprocessed/X_test',X_test)\n",
    "np.save('./preprocessed/Y_train',Y_train)\n",
    "np.save('./preprocessed/Y_test',Y_test)\n",
    "print (X.shape)\n",
    "print (Y.shape)\n",
    "\n",
    "np.save('./preprocessed/X_total',X)\n",
    "np.save('./preprocessed/Y_total',Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "alfgd78cLapt",
    "outputId": "06ac8baf-0ff9-45f6-9bee-916de9f31956"
   },
   "outputs": [],
   "source": [
    "X_train = np.load('./preprocessed/X_train.npy')\n",
    "X_test = np.load('./preprocessed/X_test.npy')\n",
    "Y_train = np.load('./preprocessed/Y_train.npy')\n",
    "Y_test = np.load('./preprocessed/Y_test.npy')\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qmcV1TT9LceC"
   },
   "outputs": [],
   "source": [
    "def average_emb(X_predicts,Y_predicts):\n",
    "    average_embeddings = {}\n",
    "    count_embeddings = {}\n",
    "    for i in range(len(X_predicts)):\n",
    "        if Y_predicts[i] not in average_embeddings:\n",
    "            average_embeddings[Y_predicts[i]] = X_predicts[i]\n",
    "            count_embeddings[Y_predicts[i]] = 1\n",
    "        else:\n",
    "            average_embeddings[Y_train[i]] += X_predicts[i]\n",
    "            count_embeddings[Y_predicts[i]] += 1\n",
    "\n",
    "    for key, value in average_embeddings.items():\n",
    "        average_embeddings[key] = average_embeddings[key]/count_embeddings[key]\n",
    "    return average_embeddings\n",
    "\n",
    "  \n",
    "def get_acurracy(X_predicts):\n",
    "    average_embeddings = average_emb(X_predicts,Y_train)\n",
    "    count = 0\n",
    "    bad_count = 0\n",
    "    for i in range(len(X_predicts)):\n",
    "        best_result = -1\n",
    "        best_val = 0\n",
    "        for key, value in average_embeddings.items():\n",
    "            result = cosine_similarity(X_predicts[i],value)\n",
    "            #print (key, Y_test[i],result)\n",
    "            if result > best_result:\n",
    "                best_result = result\n",
    "                best_val = key\n",
    "\n",
    "    if (best_val == Y_train[i]):\n",
    "        count+=1\n",
    "    else:\n",
    "        bad_count+=1\n",
    "\n",
    "    return (count/(count+bad_count))\n",
    "\n",
    "\n",
    "def make_matrix(X_train,Y_train,average_model):\n",
    "    print('making matrix')\n",
    "    X_predicts = average_model.predict(X_train,batch_size = 16,verbose = 1)\n",
    "    accuracy = get_acurracy(X_predicts)\n",
    "    matrix = np.zeros((len(X_train[0]),len(X_train[0])))\n",
    "    for i in range(len(X_predicts)):\n",
    "        matrix[i][i] = 1.0\n",
    "        for j in range(i+1,len(X_predicts)):\n",
    "            matrix[i][j] = cosine_similarity(X_predicts[i],X_predicts[j])\n",
    "            matrix[j][i] = matrix[i][j]\n",
    "    return accuracy,matrix\n",
    "\n",
    "def make_worse_triplets(matrix,X_train,Y_train):\n",
    "    anchors = np.zeros((5,len(X_train[0]),101,318))\n",
    "    positives = np.zeros((5,len(X_train[0]),101,318))\n",
    "    negatives = np.zeros((5,len(X_train[0]),101,318))\n",
    "    for x in range(len(matrix)):\n",
    "        lowest = 1.5\n",
    "        highest = -1.5\n",
    "        anchor = X_train[:,x:x+1]\n",
    "        for y in range(len(matrix)):\n",
    "            if matrix[x][y] < lowest and (Y_train[x] == Y_train[y]):\n",
    "                lowest = matrix[x][y]\n",
    "                positive = y\n",
    "            elif matrix[x][y] > highest and Y_train[x] != Y_train[y]:\n",
    "                highest = matrix[x][y]\n",
    "                negative = y\n",
    "        anchors[:,x,:,:] = X_train[:,x,:,:]\n",
    "        positives[:,x,:,:] = X_train[:,positive,:,:]\n",
    "        negatives[:,x,:,:] = X_train[:,negative,:,:]\n",
    "        #print (x,'/',len(matrix))\n",
    "    return anchors,positives,negatives\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YypFzcFELgq6"
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 32\n",
    "Y_dummy = np.empty((batch_size, 3))\n",
    "messages= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XUMLt8cIO68q"
   },
   "outputs": [],
   "source": [
    "accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 11237
    },
    "colab_type": "code",
    "id": "JZ_clDFiLjHq",
    "outputId": "15942398-4805-45d0-adb2-dc9101b9ca05"
   },
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    print (\"epoch\",i)\n",
    "    accuracy,matrix = make_matrix(X_train.tolist(),Y_train,base_model)\n",
    "    print (\"made matrix\")\n",
    "    print(\"acurracy\",accuracy)\n",
    "    anchors, positives, negatives = make_worse_triplets(matrix,X_train,Y_train)\n",
    "    start_idx = 0\n",
    "    mean_loss = 0\n",
    "    accuracies += [accuracy]\n",
    "    while (start_idx + batch_size < len(anchors[0])):\n",
    "        batch_x = anchors[:,start_idx:start_idx + batch_size].tolist()+positives[:,start_idx:start_idx + batch_size].tolist()+negatives[:,start_idx:start_idx + batch_size].tolist()\n",
    "        message = speech_model.train_on_batch(x = batch_x, y = Y_dummy)\n",
    "        mean_loss+= message[0]\n",
    "        messages+= [message]\n",
    "        if ((start_idx/batch_size)%3 == 0):\n",
    "            print (\"start_idx:\",start_idx, \",loss:\",message)\n",
    "        start_idx+=batch_size\n",
    "    if (len(anchors[0])%batch_size != 0):\n",
    "        batch_x = anchors[:,-batch_size:].tolist()+positives[:,-batch_size:].tolist()+negatives[:,-batch_size:].tolist()\n",
    "        speech_model.train_on_batch(x = batch_x, y = Y_dummy)\n",
    "    print(\"average_loss:\",(mean_loss/(len(anchors[0])/batch_size+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "QnWihRdqE2Jy",
    "outputId": "d8167f7b-dcc9-4bc7-dddd-ba570e36443f"
   },
   "outputs": [],
   "source": [
    "messages_donwload = np.array(messages)\n",
    "acc_down = np.array(accuracies)\n",
    "print (messages_donwload.shape)\n",
    "print (acc_down.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uG0aFTFeOOAa"
   },
   "outputs": [],
   "source": [
    "base_model.save(\"finalv1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yYP6uM8BORmp"
   },
   "outputs": [],
   "source": [
    "np.save('messages_download_last_50',messages_donwload)\n",
    "np.save('acc_download_last_50',acc_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "JA5KcWFWOkzm",
    "outputId": "89876571-e1a3-45f9-a330-409fab013668"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GfoJ1KMaOpM8"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('finalv1.h5')\n",
    "files.download('messages_download_last_50.npy')\n",
    "files.download('acc_download_last_50.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZ462eq69ax1"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('base_model_50plus.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "xa3yemrQ9kVp",
    "outputId": "45e4d6eb-06b1-4221-89da-c9757b3fb4cb"
   },
   "outputs": [],
   "source": [
    "print(acc_down)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled9.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
